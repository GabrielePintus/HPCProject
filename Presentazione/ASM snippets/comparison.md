# Optimization levels comparison

In this document, we will compare the **assembly** code generated by the **GCC** compiler for different optimization levels, namely none and three. We will focus only
on the `mandelbrot` function, which compute a given point in the Mandelbrot set.

## The amd64 architecture registers

Hereafter we describe the registers used in the **amd64** architecture. To be brief, we will only describe the registers used in our code.

### Special-purpose registers

- RIP (Instruction Pointer): points to the next instruction to be executed.
- RSP (Stack Pointer): points to the top of the stack.
- RBP (Base Pointer): points to the base of the current stack frame.

### General-purpose registers

| 64-bit | 32-bit | 16-bit | 
|--------|--------|--------|
| rax    | eax    | ax     |
| rdx    | edx    | dx     |
| rbp    | ebp    | bp     |
| rsp    | esp    | sp     |


### SIMD and floating-point registers

- **XMM0-XMM15**: 128-bit registers used for floating-point operations.





## The code

First, let's take a look at the original C code:

```c
1   int mandelbrot(const Complex c) {
2       int n = 0;
3       Complex z = {0, 0};
4       while ((z.x * z.x + z.y * z.y) < 4 && n < MAX_ITER) {
5           double temp = z.x * z.x - z.y * z.y + c.x;
6           z.y = 2 * z.x * z.y + c.y;
7           z.x = temp;
8           ++n;
9       }
10      return n;
11  }
```

## No optimization

The assembly code generated by the compiler with no optimization is shown below. Almost each line is commented to explain its purpose.

**Function prologue**: sets up the stack frame for the function.

```asm
mandelbrot:
.LFB6:
	.cfi_startproc
	pushq	%rbp                # Save base pointer of the calling function
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp          # Set the base pointer to the current stack pointer
	.cfi_def_cfa_register 6
	movl	$0, %eax            # Initialize EAX register to 0 (clear the register)
	movl	$0, %edx            # Initialize EDX register to 0 (clear the register)
	movq	%xmm0, %rax         # Move xmm0 (real part of c) to RAX
	movq	%xmm1, %rdx         # Move xmm1 (imaginary part of c) to RDX
	movq	%rax, -48(%rbp)     # Store RAX (real part of c) in the local variable -48(%rbp)
	movq	%rdx, -40(%rbp)     # Store RDX (imaginary part of c) in the local variable -40(%rbp)
	movl	$0, -4(%rbp)        # Initialize iteration counter (n) to 0
	pxor	%xmm0, %xmm0        # Clear xmm0 (set to zero)
	movsd	%xmm0, -32(%rbp)    # Initialize Z_real to 0.0
	pxor	%xmm0, %xmm0        # Clear xmm0 (set to zero)
	movsd	%xmm0, -24(%rbp)    # Initialize Z_imag to 0.0
	jmp	.L2                     # Jump to the beginning of the iteration check
```


**Iteration Loop**: updates the real and imaginary parts of Z and the iteration count:

```asm
.L5:
	movsd	-32(%rbp), %xmm1    # Load Z_real into xmm1
	movsd	-32(%rbp), %xmm0    # Load Z_real into xmm0
	mulsd	%xmm1, %xmm0        # Compute Z_real^2
	movsd	-24(%rbp), %xmm2    # Load Z_imag into xmm2
	movsd	-24(%rbp), %xmm1    # Load Z_imag into xmm1
	mulsd	%xmm1, %xmm2        # Compute Z_imag^2
	movapd	%xmm0, %xmm1        # Move Z_real^2 to xmm1
	subsd	%xmm2, %xmm1        # Compute Z_real^2 - Z_imag^2
	movsd	-48(%rbp), %xmm0    # Load real part of c
	addsd	%xmm1, %xmm0        # Add (Z_real^2 - Z_imag^2) to the real part of c
	movsd	%xmm0, -16(%rbp)    # Store the result as the new Z_real
	movsd	-32(%rbp), %xmm0    # Load Z_real into xmm0
	movapd	%xmm0, %xmm1        # Move Z_real to xmm1
	addsd	%xmm0, %xmm1        # Compute 2 * Z_real
	movsd	-24(%rbp), %xmm0    # Load Z_imag into xmm0
	mulsd	%xmm0, %xmm1        # Compute 2 * Z_real * Z_imag
	movsd	-40(%rbp), %xmm0    # Load imaginary part of c
	addsd	%xmm1, %xmm0        # Add (2 * Z_real * Z_imag) to the imaginary part of c
	movsd	%xmm0, -24(%rbp)    # Store the result as the new Z_imag
	movsd	-16(%rbp), %xmm0    # Load the new Z_real
	movsd	%xmm0, -32(%rbp)    # Store it back to Z_real
	addl	$1, -4(%rbp)        # Increment the iteration counter
```

**Iteration check**: checks if the iteration count is less than the maximum number of iterations and if the magnitude of Z is less than 2:

```asm
.L2:
	movsd	-32(%rbp), %xmm1    # Load Z_real into xmm1
	movsd	-32(%rbp), %xmm0    # Load Z_real into xmm0
	mulsd	%xmm0, %xmm1        # Compute Z_real^2
	movsd	-24(%rbp), %xmm2    # Load Z_imag into xmm2
	movsd	-24(%rbp), %xmm0    # Load Z_imag into xmm0
	mulsd	%xmm2, %xmm0        # Compute Z_imag^2
	addsd	%xmm0, %xmm1        # Compute |Z|^2 = Z_real^2 + Z_imag^2
	movsd	.LC1(%rip), %xmm0   # Load the constant 4.0 into xmm0 (2^2 = 4)
	comisd	%xmm1, %xmm0        # Compare |Z|^2 with 4.0
	jbe	.L3                     # If |Z|^2 <= 4.0, jump to .L3 (finish)
	cmpl	$65534, -4(%rbp)    # Compare iteration count with 65534
	jle	.L5                     # If iteration count <= 65534, jump to .L5 (iterate)
```

**Function epilogue**: cleans up the stack frame and returns the iteration count:

```asm
.L3:
	movl	-4(%rbp), %eax      # Move the iteration count to EAX (return value)
	popq	%rbp                # Restore the caller's base pointer
	.cfi_def_cfa 7, 8
	ret                         # Return from the function
	.cfi_endproc
.LFE6:
	.size	mandelbrot, .-mandelbrot
```

## Optimization level 3

The assembly code generated by the compiler with optimization level 3 is shown below. Almost each line is commented to explain its purpose.

**Function prologue**: sets up the stack frame for the function.
```asm
mandelbrot:
.LFB22:
	.cfi_startproc
	pxor	%xmm2, %xmm2         # Clear xmm2 (set to zero)
	movsd	.LC2(%rip), %xmm7    # Load constant 4.0 into xmm7 (2^2 = 4)
	xorl	%eax, %eax           # Clear EAX (set iteration count to 0)
	movapd	%xmm2, %xmm5         # Initialize xmm5 to 0 (Z_real)
	movapd	%xmm2, %xmm6         # Initialize xmm6 to 0 (Z_imag)
	movapd	%xmm2, %xmm3         # Initialize xmm3 to 0 (temporary Z_real*Z_imag)
	jmp	.L23                     # Jump to iteration check
	.p2align 4,,10
	.p2align 3
```

**Iteration Loop**: updates the real and imaginary parts of Z and the iteration count:

```asm
.L26:
	cmpl	$65535, %eax         # Compare iteration count with 65535
	je	.L20                     # Jump to end if iteration count >= 65535
.L23:
	movapd	%xmm5, %xmm4         # Move Z_real to xmm4
	subsd	%xmm6, %xmm3         # Compute Z_real^2 - Z_imag^2 and store in xmm3
	addl	$1, %eax             # Increment iteration count
	addsd	%xmm4, %xmm4         # Double Z_real
	movapd	%xmm3, %xmm5         # Move result to xmm5
	mulsd	%xmm4, %xmm2         # Compute 2 * Z_real * Z_imag
	addsd	%xmm0, %xmm5         # Add real part of c to xmm5
	movapd	%xmm5, %xmm3         # Move updated Z_real to xmm3
	mulsd	%xmm5, %xmm3         # Compute (Z_real_new)^2
	addsd	%xmm1, %xmm2         # Add imaginary part of c to xmm2
	movapd	%xmm2, %xmm6         # Move updated Z_imag to xmm6
	mulsd	%xmm2, %xmm6         # Compute (Z_imag_new)^2
	movapd	%xmm3, %xmm4         # Move (Z_real_new)^2 to xmm4
	addsd	%xmm6, %xmm4         # Add (Z_imag_new)^2 to xmm4 (|Z_new|^2)
	comisd	%xmm4, %xmm7         # Compare |Z_new|^2 with 4.0
	ja	.L26                     # If |Z_new|^2 < 4.0, continue iterations
```

**Function epilogue**: cleans up the stack frame and returns the iteration count:

```asm
.L20:
	ret
	.cfi_endproc
.LFE22:
	.size	mandelbrot, .-mandelbrot
	.p2align 4
	.globl	mandelbrot_set
	.type	mandelbrot_set, @function
```


## Comparison

Even without a deep analysis, we can see that the optimized version do
not use the stack as as the basic version. This imply that we have less
memory accesses and therefore less latency. Moreover, we obviously have less instructions to execute. 


### Alignment

The optimized code exploits the `p2align` directive to align the code to a 16-byte boundary, with a maximum of 10 bytes of padding. This optimizes the memory access pattern *reducing the number of cache misses*. 


```
❯ perf stat ./mandelbrot_basic

 Performance counter stats for './mandelbrot_basic':

         27.932,06 msec task-clock:u                     #    7,790 CPUs utilized                  
               324      page-faults:u                    #   11,600 /sec                      
    49.652.936.015      cycles:u                         #    1,778 GHz                       
    55.249.868.058      instructions:u                   #    1,11  insn per cycle            
     3.251.897.871      branches:u                       #  116,422 M/sec                     
            98.030      branch-misses:u                  #    0,00% of all branches           

       3,585651433 seconds time elapsed
      27,708242000 seconds user
       0,044305000 seconds sys
```
```
❯ perf stat ./mandelbrot_optimized

 Performance counter stats for './mandelbrot_optimized':

         12.793,09 msec task-clock:u                     #    7,818 CPUs utilized             
               339      page-faults:u                    #   26,499 /sec                      
    22.696.524.521      cycles:u                         #    1,774 GHz                       
    29.256.559.200      instructions:u                   #    1,29  insn per cycle            
     3.251.621.143      branches:u                       #  254,170 M/sec                     
            95.970      branch-misses:u                  #    0,00% of all branches           

       1,636330464 seconds time elapsed
      12,665655000 seconds user
       0,024710000 seconds sys
```

We can notice that the optimized version has less cache accesses in general, due to the reduced usage of the stack, and less cache misses. This is reflected in the user time, which is more than twice as fast as the basic version. This is reflected in the total time elapsed as well.

The optimized version can use the `movapd` instruction more often than the basic version, which is a SIMD instruction that moves a packed double-precision floating-point value from the source operand to the destination operand. Unlinke `movsd`, which moves 64 bits at once (one double-precision floating-point value), `movapd` moves 128 bits at once (two double-precision floating-point values).